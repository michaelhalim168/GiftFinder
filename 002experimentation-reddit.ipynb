{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use reddit-scrape.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tech Data\n",
    "\n",
    "tech_reddit = Reddit(user_name, password, client_id, secret_key, user_agent)\n",
    "tech_reddit.get_posts('Electronics/Gadgets', ['tech', 'webdev', 'techsupport', 'web_design', 'gadgets', 'learnprogramming'])\n",
    "tech_df = tech_reddit.posts\n",
    "\n",
    "# Sports Data\n",
    "\n",
    "sports_reddit = Reddit(user_name, password, client_id, secret_key, user_agent)\n",
    "sports_reddit.get_posts('Sports', ['sports', 'nba', 'soccer', 'nfl', 'baseball', 'hockey'])\n",
    "sports_df = sports_reddit.posts\n",
    "\n",
    "# Travel Data\n",
    "\n",
    "travel_reddit = Reddit(user_name, password, client_id, secret_key, user_agent)\n",
    "travel_reddit.get_posts('Travel', ['Shoestring', 'travel', 'wanderlust', 'solotravel'])\n",
    "travel_df = travel_reddit.posts\n",
    "\n",
    "# Art Data\n",
    "\n",
    "art_reddit = Reddit(user_name, password, client_id, secret_key, user_agent)\n",
    "art_reddit.get_posts('Arts', ['ArtFundamentals', 'Art' , 'Sketchpad', 'ArtStore', 'ArtTools'])\n",
    "art_df = art_reddit.posts\n",
    "\n",
    "# Music Data\n",
    "\n",
    "music_reddit = Reddit(user_name, password, client_id, secret_key, user_agent)\n",
    "music_reddit.get_posts('Music', ['Music', 'ListenToThis', 'DubStep', 'HipHopHeads', 'Guitar', 'Electronics', 'Vinyl'])\n",
    "music_df = music_reddit.posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = pd.concat([tech_df, sports_df, travel_df, art_df, music_df])\n",
    "combined_data.to_csv('datasets/reddit-categories1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Backup cleaning functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuations = string.punctuation\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "def remove_punc(text):\n",
    "    return ''.join([word for word in text if word not in punctuations])\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    return [word for word in text.split() if word not in stopwords]\n",
    "\n",
    "def convert_lowercase(text):\n",
    "    return ''.join([word.lower() for word in text])\n",
    "\n",
    "def preprocess(text):\n",
    "    text = re.sub(r'\\b\\w{1,2}\\b', '', text)\n",
    "    text = remove_punc(text)\n",
    "    text = convert_lowercase(text)\n",
    "    text = remove_stopwords(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def spacy_lemmatize(text):\n",
    "    if type(text) == list:\n",
    "        doc = nlp(u\"{}\".format(' '.join(text)))\n",
    "    else:\n",
    "        doc = nlp(u\"{}\".format(text))\n",
    "    lemmatized = list()\n",
    "    for token in doc:\n",
    "        lemmatized.append(token.lemma_)\n",
    "    \n",
    "    return lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit = pd.read_csv('datasets/reddit-categories1.csv')\n",
    "reddit.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "reddit.fillna('', inplace=True)\n",
    "reddit['full-text'] = reddit['title'] + reddit['body']\n",
    "reddit['clean-text'] = reddit['full-text'].map(preprocess).map(spacy_lemmatize).apply(lambda x: ' '.join([word for word in x if word not in punctuations])).map(str)\n",
    "data = reddit[['category', 'clean-text']]\n",
    "data.to_csv('datasets/train-test-data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['clean-text']\n",
    "y = data['category']\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "ref = set(zip(data['category'].to_numpy(), y))\n",
    "\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, stratify=y)\n",
    "tfidf = TfidfVectorizer()\n",
    "X_train = tfidf.fit_transform(X_train)\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train, y_train)\n",
    "X_test = tfidf.transform(X_test)\n",
    "nb.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tests = ['Such a peaceful retreat, close to the mountains and close to the ocean as well. The perfect combination', \n",
    "         \"Our home for the next 5 nights in Albania\", \n",
    "        \"Very pretty little Pandora Clock, with the large Z566M Nixie tubes. Made out of an old Victorian sewing box, light sensor hidden in the keyhole to dim the tubes at night!\", #misclassfied, should be more arts, not music \n",
    "        \"It's an honor that I've been chosen as the top 10 in the Art competition.#arts #art #artaccount #artist  #paint I I'm grateful for this opportunity. I honestly didn't expect to be selected but I'm glad I joined this. There's still more to go\", #hashtags really help\n",
    "        \"No one would've batted an eye if Odell Beckham started camp on the PUP list. That's the normal time table.Odell beat it.\",\n",
    "        'Reverse engineering generative models by Facebook AI can identify deepfakes and track their origin! Cool, eh? We need that for all sorts of deepfakes, especially audio',\n",
    "        '\"WONDER\" By me :)Yet another song I made, hope you guys like it!(Soundcloud link in thread)',\n",
    "        'meet me where the #music meets the #sea....',\n",
    "        'A winning sunset  #vacation', #without hashtag, classified as art\n",
    "        'Happy #HumpDay from the beach Umbrella on ground Wednesday night moon',\n",
    "        'Such a peaceful retreat, close to the mountains and close to the ocean as well. The perfect combination',\n",
    "        'NEW VIDEO - The iPhone 13 Models!',\n",
    "        'Tesla Model S PLAID Impressions: Re-Inventing the Wheel!'\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tests_full = ['Such a peaceful retreat, close to the mountains and close to the ocean as well. The perfect combination', \n",
    "         \"Our home for the next 5 nights in Albania\", \n",
    "        \"No one would've batted an eye if Odell Beckham started camp on the PUP list. That's the normal time table.Odell beat it.\",\n",
    "        'Happy #HumpDay from the beach Umbrella on ground Wednesday night moon',\n",
    "        'Such a peaceful retreat, close to the mountains and close to the ocean as well. The perfect combination',\n",
    "        'NEW VIDEO - The iPhone 13 Models!',\n",
    "        'Tesla Model S PLAID Impressions: Re-Inventing the Wheel!'\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = ' '.join(tests_full)\n",
    "user_input = preprocess(user_input)\n",
    "user_input = spacy_lemmatize(user_input)\n",
    "user_input = ' '.join(user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = tfidf.transform([user_input])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb.predict_proba(user_input)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lhl-bootcamp",
   "language": "python",
   "name": "lhl-bootcamp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
