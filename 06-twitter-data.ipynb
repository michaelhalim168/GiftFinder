{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gift Recommender Engine: Obtain Twitter Users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries and Scrape User Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import pickle\n",
    "from scripts.keys import *\n",
    "\n",
    "def get_user_tweets(user_id, consumer_key, consumer_secret, access_token, access_token_secret):\n",
    "    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "    auth.set_access_token(access_token, access_token_secret)\n",
    "    api = tweepy.API(auth)\n",
    "\n",
    "    tweets = api.user_timeline(screen_name=user_id, count=200, include_rts=True, tweet_mode='extended')\n",
    "\n",
    "    return tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter = TwitterKeys()\n",
    "consumer_key = twitter.consumer_key\n",
    "consumer_secret = twitter.consumer_secret\n",
    "access_token = twitter.access_token\n",
    "access_secret = twitter.access_secret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "user_id = ''\n",
    "\n",
    "#tweets = get_user_tweets(user_id, consumer_key, consumer_secret, access_token, access_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = ''\n",
    "\n",
    "tweets = get_user_tweets(user_id, consumer_key, consumer_secret, access_token, access_secret)\n",
    "\n",
    "filename = open('nisha.sav', 'wb')\n",
    "pickle.dump(tweets, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def user_tweet_df(filename, username):\n",
    "    \n",
    "    tweets = pickle.load(open(filename, 'rb'))\n",
    "    \n",
    "    all_tweets = []\n",
    "    username = tweets[0]._json['user']['screen_name']\n",
    "    for tweet in tweets:\n",
    "        all_tweets.append(tweet._json['full_text'])\n",
    "        \n",
    "    df = pd.DataFrame({'user': username, 'Tweet Content': all_tweets})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "sohaib_df = user_tweet_df('sohaib.sav', 'rb')\n",
    "sohaib_df.rename(columns={'tweets': 'Tweet Content'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "carr1eg_df = user_tweet_df('carr.sav', 'rb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "user3_df = user_tweet_df('bintur.sav', 'rb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "sarah_df = user_tweet_df('sarah.sav', 'rb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "kyle_df = user_tweet_df('kyle.sav', 'rb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "may_df = user_tweet_df('may.sav', 'rb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "marie_df = user_tweet_df('marie.sav', 'rb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "nisha_df = user_tweet_df('nisha.sav', 'rb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "import spacy\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "stopwords.extend(['im', \"oh\", \"i'm\", \"lol\", \"gonna\", 'ill'])\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def spacy_lemmatize(text):\n",
    "    if type(text) == list:\n",
    "        doc = nlp(u\"{}\".format(' '.join(text)))\n",
    "    else:\n",
    "        doc = nlp(u\"{}\".format(text))\n",
    "    lemmatized = list()\n",
    "    for token in doc:\n",
    "        lemmatized.append(token.lemma_)\n",
    "    \n",
    "    return lemmatized\n",
    "\n",
    "def deEmojify(text):\n",
    "    regrex_pattern = re.compile(pattern = \"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           \"]+\", flags = re.UNICODE)\n",
    "    return regrex_pattern.sub(r'',text)\n",
    "\n",
    "\n",
    "def tweet_preprocess(text):\n",
    "    text=re.sub(r'http\\S+', '',text)\n",
    "    text = re.sub('@[^\\s]+','',text)\n",
    "    text = re.sub('&lt;/?[a-z]+&gt;', '', text)\n",
    "    text = text.replace('&amp', '&')\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
    "    text = deEmojify(text)\n",
    "    text = text.split() #split into list\n",
    "    #text = [re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', s, flags=re.MULTILINE) for s in text] #remove any links\n",
    "    #text = [re.sub('@[^\\s]+','', s) for s in text] #remove @\n",
    "    text = [s.lower() for s in text] #convert every character into lowercase\n",
    "    #text = [re.sub(rf\"[{string.punctuation}]\", \" \", s) for s in text] #remove punctuations\n",
    "    text = [re.sub(r'[0-9]', ' ', s) for s in text] #remove all digits\n",
    "    text = ' '.join(text)  #resplits\n",
    "    text = [s for s in text.split() if len(s) >= 2] #removes words with one word length\n",
    "    text = [s for s in text if s not in stopwords] #remove all stopwords\n",
    "    text = ' '.join(spacy_lemmatize(text)) #lemmatize text using spacy and join into a string\n",
    "    text = ' '.join([s for s in text.split() if len(s) > 2])\n",
    "    return text\n",
    "\n",
    "\n",
    "class TweetCategory:\n",
    "\n",
    "    def __init__(self, model, vectorizer, tweet_data, reference):\n",
    "        self.data = tweet_data\n",
    "        self.model = model\n",
    "        self.vectorizer = vectorizer\n",
    "        self.ref = reference\n",
    "        self.analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "    def process_user_tweets(self):\n",
    "        self.data['clean-tweet'] = self.data['Tweet Content'].map(tweet_preprocess)\n",
    "        self.data = self.data[['Tweet Content', 'clean-tweet']].rename(columns={'Tweet Content': 'tweet'})\n",
    "\n",
    "        self.data['vader-sentiment'] = self.data['tweet'].apply(lambda x: self.analyzer.polarity_scores(x))\n",
    "        self.data['vader-pos'] = self.data['vader-sentiment'].apply(lambda x: x['pos'])\n",
    "        self.data['vader-neu'] = self.data['vader-sentiment'].apply(lambda x: x['neu'])\n",
    "        self.data['vader-neg'] = self.data['vader-sentiment'].apply(lambda x: x['neg'])\n",
    "        self.data['vader-compound'] = self.data['vader-sentiment'].apply(lambda x: x['compound'])\n",
    "\n",
    "\n",
    "    def predict_topics(self, sentiment_thresh, confidence_thresh):\n",
    "        self.predict_df = self.data[(self.data['vader-compound'] >= sentiment_thresh) & (self.data['clean-tweet'] != '')]\n",
    "        \n",
    "        tweets_transformed = self.vectorizer.transform(self.predict_df['clean-tweet'])\n",
    "        predicted_category = self.model.predict(tweets_transformed)\n",
    "\n",
    "        p = np.array(self.model.decision_function(tweets_transformed))\n",
    "        probability = np.exp(p)/np.sum(np.exp(p), axis=1, keepdims=True)\n",
    "        probability_list = [max(prob) for prob in probability]\n",
    "\n",
    "        self.predict_df['predicted'] = predicted_category\n",
    "        self.predict_df['probability'] = probability_list\n",
    "        self.predict_df['predicted'] = self.predict_df['predicted'].apply(lambda x: self.ref[x])\n",
    "\n",
    "        top_categories = self.predict_df[self.predict_df['probability'] >= confidence_thresh]['predicted'].value_counts()[:3]       \n",
    "\n",
    "        return top_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Naive Bayes Model\n",
    "filename = open('models/nb_baseline2.sav', 'rb')\n",
    "nb = pickle.load(filename)\n",
    "\n",
    "# Support Vector Classifier Model\n",
    "filename = open('models/linear_svc_baseline2.sav', 'rb')\n",
    "ovr_svc = pickle.load(filename)\n",
    "\n",
    "# Import Vectorizer\n",
    "filename = open('models/tfidf_vectorizer2.sav', 'rb')\n",
    "tfidf_model = pickle.load(filename)\n",
    "\n",
    "# Import Reference Dictionary\n",
    "filename = open('models/reference-dict.pickle', 'rb')\n",
    "ref = pickle.load(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = {v: k for k, v in ref.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected: Art, Books, Food, Household/Decor/Cooking, Movies, Music, Nature/Animals/Green, Sports, Travel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "sohaib_class = TweetCategory(ovr_svc, tfidf_model, sohaib_df, key)\n",
    "sohaib_class.process_user_tweets()\n",
    "top_topics = sohaib_class.predict_topics(0, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sports                 4\n",
       "Nature                 2\n",
       "Electronics/Gadgets    2\n",
       "Name: predicted, dtype: int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected: Travel, Work, Self-care, Tech, Books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "carr_class = TweetCategory(ovr_svc, tfidf_model, carr1eg_df, key)\n",
    "carr_class.process_user_tweets()\n",
    "top_topics = carr_class.predict_topics(0, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Electronics/Gadgets    1\n",
       "Name: predicted, dtype: int64"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected: Food, Tech, Business, Household/Cooking, Self-Care"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "user3_class = TweetCategory(ovr_svc, tfidf_model, user3_df, key)\n",
    "user3_class.process_user_tweets()\n",
    "top_topics = user3_class.predict_topics(0, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Food                   2\n",
       "Alcohol                2\n",
       "Electronics/Gadgets    2\n",
       "Name: predicted, dtype: int64"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>clean-tweet</th>\n",
       "      <th>vader-sentiment</th>\n",
       "      <th>vader-pos</th>\n",
       "      <th>vader-neu</th>\n",
       "      <th>vader-neg</th>\n",
       "      <th>vader-compound</th>\n",
       "      <th>predicted</th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>I use it to cook everything https://t.co/4qZOW...</td>\n",
       "      <td>use cook everything</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Food</td>\n",
       "      <td>0.275017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>Coconut breaded shrimp 😍😍\\nAlhamdulilaah for food</td>\n",
       "      <td>coconut bread shrimp alhamdulilaah food</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.667, 'pos': 0.333, 'comp...</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7184</td>\n",
       "      <td>Food</td>\n",
       "      <td>0.688882</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 tweet  \\\n",
       "38   I use it to cook everything https://t.co/4qZOW...   \n",
       "123  Coconut breaded shrimp 😍😍\\nAlhamdulilaah for food   \n",
       "\n",
       "                                 clean-tweet  \\\n",
       "38                       use cook everything   \n",
       "123  coconut bread shrimp alhamdulilaah food   \n",
       "\n",
       "                                       vader-sentiment  vader-pos  vader-neu  \\\n",
       "38   {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...      0.000      1.000   \n",
       "123  {'neg': 0.0, 'neu': 0.667, 'pos': 0.333, 'comp...      0.333      0.667   \n",
       "\n",
       "     vader-neg  vader-compound predicted  probability  \n",
       "38         0.0          0.0000      Food     0.275017  \n",
       "123        0.0          0.7184      Food     0.688882  "
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user3 = user3_class.predict_df\n",
    "user3[(user3['predicted'] == 'Food') & (user3['probability'] >= 0.2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected: Music (likes to sing, great taste in music), Self-care (into make-up and fashion and things like that), Business, Art"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "user4_class = TweetCategory(ovr_svc, tfidf_model, sarah_df, key)\n",
    "user4_class.process_user_tweets()\n",
    "top_topics = user4_class.predict_topics(0, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Business     3\n",
       "Self-care    2\n",
       "Music        2\n",
       "Name: predicted, dtype: int64"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "#user4_class.predict_df[-10:]['tweet'].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected: Art, Tech, Food, Coffee, Gaming, Household, Movies, Music, Sports, Travel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "user5_class = TweetCategory(ovr_svc, tfidf_model, kyle_df, key)\n",
    "user5_class.process_user_tweets()\n",
    "top_topics = user5_class.predict_topics(0, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Coffee    13\n",
       "Sports    11\n",
       "Nature     4\n",
       "Name: predicted, dtype: int64"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected: Music (likes to sing), Self-care (always stressed), Work or Business (very work oriented), Art (likes to draw). Bad topics: books, sports, alcohol, coffee, household."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "user6_class = TweetCategory(ovr_svc, tfidf_model, may_df, key)\n",
    "user6_class.process_user_tweets()\n",
    "top_topics = user6_class.predict_topics(0, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>clean-tweet</th>\n",
       "      <th>vader-sentiment</th>\n",
       "      <th>vader-pos</th>\n",
       "      <th>vader-neu</th>\n",
       "      <th>vader-neg</th>\n",
       "      <th>vader-compound</th>\n",
       "      <th>predicted</th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @ltc_angel: If #bitcoin keeps dropping like...</td>\n",
       "      <td>bitcoin keep drop like may create onlyfan</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.753, 'pos': 0.247, 'comp...</td>\n",
       "      <td>0.247</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.5574</td>\n",
       "      <td>Business</td>\n",
       "      <td>0.423039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>RT @jaxkkkie: I stopped fuckin with a lot of p...</td>\n",
       "      <td>stop fuckin lot people life great lil boring g...</td>\n",
       "      <td>{'neg': 0.11, 'neu': 0.601, 'pos': 0.29, 'comp...</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.601</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.7964</td>\n",
       "      <td>Self-care</td>\n",
       "      <td>0.208391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>RT @majestcbitch: SOMEONE SAID “WAIT START AGA...</td>\n",
       "      <td>someone say wait start record lmaoooooo</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Music</td>\n",
       "      <td>0.400637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Your mind is always eavesdropping on your self...</td>\n",
       "      <td>mind always eavesdrop self talk think positive...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.644, 'pos': 0.356, 'comp...</td>\n",
       "      <td>0.356</td>\n",
       "      <td>0.644</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.8020</td>\n",
       "      <td>Self-care</td>\n",
       "      <td>0.307861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Accept that you will not find your comfort zon...</td>\n",
       "      <td>accept find comfort zone people people change ...</td>\n",
       "      <td>{'neg': 0.068, 'neu': 0.78, 'pos': 0.151, 'com...</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.6237</td>\n",
       "      <td>Self-care</td>\n",
       "      <td>0.288829</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                tweet  \\\n",
       "0   RT @ltc_angel: If #bitcoin keeps dropping like...   \n",
       "66  RT @jaxkkkie: I stopped fuckin with a lot of p...   \n",
       "75  RT @majestcbitch: SOMEONE SAID “WAIT START AGA...   \n",
       "86  Your mind is always eavesdropping on your self...   \n",
       "94  Accept that you will not find your comfort zon...   \n",
       "\n",
       "                                          clean-tweet  \\\n",
       "0           bitcoin keep drop like may create onlyfan   \n",
       "66  stop fuckin lot people life great lil boring g...   \n",
       "75            someone say wait start record lmaoooooo   \n",
       "86  mind always eavesdrop self talk think positive...   \n",
       "94  accept find comfort zone people people change ...   \n",
       "\n",
       "                                      vader-sentiment  vader-pos  vader-neu  \\\n",
       "0   {'neg': 0.0, 'neu': 0.753, 'pos': 0.247, 'comp...      0.247      0.753   \n",
       "66  {'neg': 0.11, 'neu': 0.601, 'pos': 0.29, 'comp...      0.290      0.601   \n",
       "75  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...      0.000      1.000   \n",
       "86  {'neg': 0.0, 'neu': 0.644, 'pos': 0.356, 'comp...      0.356      0.644   \n",
       "94  {'neg': 0.068, 'neu': 0.78, 'pos': 0.151, 'com...      0.151      0.780   \n",
       "\n",
       "    vader-neg  vader-compound  predicted  probability  \n",
       "0       0.000          0.5574   Business     0.423039  \n",
       "66      0.110          0.7964  Self-care     0.208391  \n",
       "75      0.000          0.0000      Music     0.400637  \n",
       "86      0.000          0.8020  Self-care     0.307861  \n",
       "94      0.068          0.6237  Self-care     0.288829  "
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "may_df = user6_class.predict_df\n",
    "may_df[may_df['probability'] >= 0.2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected: Tech/Work/Business (she likes psychology), Nature (she likes animals and shes vegan), Books (she's really smart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "user7_class = TweetCategory(ovr_svc, tfidf_model, marie_df, key)\n",
    "user7_class.process_user_tweets()\n",
    "top_topics = user7_class.predict_topics(0, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Electronics/Gadgets    3\n",
       "Work                   2\n",
       "Music                  1\n",
       "Name: predicted, dtype: int64"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>clean-tweet</th>\n",
       "      <th>vader-sentiment</th>\n",
       "      <th>vader-pos</th>\n",
       "      <th>vader-neu</th>\n",
       "      <th>vader-neg</th>\n",
       "      <th>vader-compound</th>\n",
       "      <th>predicted</th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>RT @metzpsych: SO MANY OPEN DATA SETS FOR TEAC...</td>\n",
       "      <td>many open datum set teach research awesome</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.788, 'pos': 0.212, 'comp...</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.788</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.7034</td>\n",
       "      <td>Electronics/Gadgets</td>\n",
       "      <td>0.221494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>😍 Great opportunity to get into #dataanalysis ...</td>\n",
       "      <td>great opportunity get dataanalysis without pro...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.541, 'pos': 0.459, 'comp...</td>\n",
       "      <td>0.459</td>\n",
       "      <td>0.541</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.8805</td>\n",
       "      <td>Electronics/Gadgets</td>\n",
       "      <td>0.318611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>@chartgerink *googles pull requests* 😂</td>\n",
       "      <td>google pull request</td>\n",
       "      <td>{'neg': 0.15, 'neu': 0.551, 'pos': 0.299, 'com...</td>\n",
       "      <td>0.299</td>\n",
       "      <td>0.551</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>Electronics/Gadgets</td>\n",
       "      <td>0.279361</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                tweet  \\\n",
       "45  RT @metzpsych: SO MANY OPEN DATA SETS FOR TEAC...   \n",
       "56  😍 Great opportunity to get into #dataanalysis ...   \n",
       "73             @chartgerink *googles pull requests* 😂   \n",
       "\n",
       "                                          clean-tweet  \\\n",
       "45         many open datum set teach research awesome   \n",
       "56  great opportunity get dataanalysis without pro...   \n",
       "73                                google pull request   \n",
       "\n",
       "                                      vader-sentiment  vader-pos  vader-neu  \\\n",
       "45  {'neg': 0.0, 'neu': 0.788, 'pos': 0.212, 'comp...      0.212      0.788   \n",
       "56  {'neg': 0.0, 'neu': 0.541, 'pos': 0.459, 'comp...      0.459      0.541   \n",
       "73  {'neg': 0.15, 'neu': 0.551, 'pos': 0.299, 'com...      0.299      0.551   \n",
       "\n",
       "    vader-neg  vader-compound            predicted  probability  \n",
       "45       0.00          0.7034  Electronics/Gadgets     0.221494  \n",
       "56       0.00          0.8805  Electronics/Gadgets     0.318611  \n",
       "73       0.15          0.4404  Electronics/Gadgets     0.279361  "
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "marie = user7_class.predict_df\n",
    "marie[(marie['predicted'] == 'Electronics/Gadgets') & (marie['probability'] >= 0.2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>clean-tweet</th>\n",
       "      <th>vader-sentiment</th>\n",
       "      <th>vader-pos</th>\n",
       "      <th>vader-neu</th>\n",
       "      <th>vader-neg</th>\n",
       "      <th>vader-compound</th>\n",
       "      <th>predicted</th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RT @StudentIOS: Calling #students of the #Neth...</td>\n",
       "      <td>call student netherlandsrecent graduate dutch ...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.892, 'pos': 0.108, 'comp...</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.892</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3182</td>\n",
       "      <td>Nature</td>\n",
       "      <td>0.093215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>RT @jtrialerror: You have ONE WEEK left to reg...</td>\n",
       "      <td>one week leave register openscience ranking de...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.889, 'pos': 0.111, 'comp...</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3595</td>\n",
       "      <td>Nature</td>\n",
       "      <td>0.095111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>RT @womensart1: 'Smoothie and Pegasus', two of...</td>\n",
       "      <td>smoothie pegasus two artist helga stentzel clo...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Nature</td>\n",
       "      <td>0.145242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>RT @ChelseaParlett: your model isn’t revolutio...</td>\n",
       "      <td>model revolutionary overfit</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Nature</td>\n",
       "      <td>0.093911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>RT @SAPoliceNews: ‼️New Dog Operations initiat...</td>\n",
       "      <td>new dog operation initiative announce small ar...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Nature</td>\n",
       "      <td>0.207651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>RT @chrisdc77: This is remarkable. I look forw...</td>\n",
       "      <td>remarkable look forward see response one</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.806, 'pos': 0.194, 'comp...</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5574</td>\n",
       "      <td>Nature</td>\n",
       "      <td>0.093791</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 tweet  \\\n",
       "9    RT @StudentIOS: Calling #students of the #Neth...   \n",
       "20   RT @jtrialerror: You have ONE WEEK left to reg...   \n",
       "41   RT @womensart1: 'Smoothie and Pegasus', two of...   \n",
       "52   RT @ChelseaParlett: your model isn’t revolutio...   \n",
       "72   RT @SAPoliceNews: ‼️New Dog Operations initiat...   \n",
       "133  RT @chrisdc77: This is remarkable. I look forw...   \n",
       "\n",
       "                                           clean-tweet  \\\n",
       "9    call student netherlandsrecent graduate dutch ...   \n",
       "20   one week leave register openscience ranking de...   \n",
       "41   smoothie pegasus two artist helga stentzel clo...   \n",
       "52                         model revolutionary overfit   \n",
       "72   new dog operation initiative announce small ar...   \n",
       "133           remarkable look forward see response one   \n",
       "\n",
       "                                       vader-sentiment  vader-pos  vader-neu  \\\n",
       "9    {'neg': 0.0, 'neu': 0.892, 'pos': 0.108, 'comp...      0.108      0.892   \n",
       "20   {'neg': 0.0, 'neu': 0.889, 'pos': 0.111, 'comp...      0.111      0.889   \n",
       "41   {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...      0.000      1.000   \n",
       "52   {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...      0.000      1.000   \n",
       "72   {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...      0.000      1.000   \n",
       "133  {'neg': 0.0, 'neu': 0.806, 'pos': 0.194, 'comp...      0.194      0.806   \n",
       "\n",
       "     vader-neg  vader-compound predicted  probability  \n",
       "9          0.0          0.3182    Nature     0.093215  \n",
       "20         0.0          0.3595    Nature     0.095111  \n",
       "41         0.0          0.0000    Nature     0.145242  \n",
       "52         0.0          0.0000    Nature     0.093911  \n",
       "72         0.0          0.0000    Nature     0.207651  \n",
       "133        0.0          0.5574    Nature     0.093791  "
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "marie[marie['predicted'] == 'Nature']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/lhl-bootcamp/lib/python3.7/site-packages/pandas/core/frame.py:3607: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._set_item(key, value)\n"
     ]
    }
   ],
   "source": [
    "user8_class = TweetCategory(ovr_svc, tfidf_model, nisha_df, key)\n",
    "user8_class.process_user_tweets()\n",
    "top_topics = user8_class.predict_topics(0, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Books     6\n",
       "Nature    3\n",
       "Work      2\n",
       "Name: predicted, dtype: int64"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lhl-bootcamp",
   "language": "python",
   "name": "lhl-bootcamp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
